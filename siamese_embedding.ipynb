{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "siamese_embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlBmnY9i8FbW"
      },
      "source": [
        "# Image Embeddings\n",
        "\n",
        "**Authors:** Itamar Zaltsman<br>\n",
        "**Date created:** 2021/06/12<br>\n",
        "**Description:** Creating image embeddings using Siamese netwrok model."
      ],
      "id": "ZlBmnY9i8FbW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AtKB77X743G"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Our project goal is to find similar products in large datasets. It may be for the use of a company which wants to ensure they provide the best prices or a customer who wants to find alternatives.\n",
        "\n",
        "In both cases, we want the results to be relevant in aspect of time.\n",
        "Assuming we already know the main retailers we will be working with, we can reduce significantly the runtime by preparing image embeddings in advance.\n"
      ],
      "id": "9AtKB77X743G"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQQDqoaVGedz"
      },
      "source": [
        "## Setup"
      ],
      "id": "CQQDqoaVGedz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca0346e0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import metrics\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications import resnet\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import pandas as pd\n",
        "\n",
        "target_shape = (200, 200)"
      ],
      "id": "ca0346e0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12e3983b",
        "outputId": "9b437ab1-3e55-4d04-838c-fa04445f730f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "12e3983b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JL9mmrgGwUh"
      },
      "source": [
        "## Load datasets\n",
        "\n",
        "Loading zip file file with all images 'train_images.zip' and 3 csv files:\n",
        "\n",
        "  * `X_train.csv` contains path to the images that the model was trained on.\n",
        "  * `X_val.csv` contains path to the images that we will use to evaluate our model.\n",
        "  * `X_test.csv` contains path to the images that we will use as a test set."
      ],
      "id": "0JL9mmrgGwUh"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a59b80e"
      },
      "source": [
        "! unzip /content/drive/MyDrive/ITC/final_project/Shopee/data/train_images.zip\n",
        "\n",
        "! mkdir train_images\n",
        "! mv *.jpg train_images"
      ],
      "id": "0a59b80e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc776452",
        "outputId": "6f7f9576-bbde-4b55-f4ca-10b7c60c0565"
      },
      "source": [
        "X_train = pd.read_csv('/content/drive/MyDrive/ITC/final_project/Shopee/data/X_train.csv')\n",
        "X_val = pd.read_csv('/content/drive/MyDrive/ITC/final_project/Shopee/data/X_val.csv')\n",
        "X_test = pd.read_csv('/content/drive/MyDrive/ITC/final_project/Shopee/data/X_test.csv')\n",
        "\n",
        "X_train.shape, X_val.shape, X_test.shape"
      ],
      "id": "bc776452",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((27444, 6), (3357, 6), (3449, 6))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buKLbgN2K2A-"
      },
      "source": [
        "\n",
        "## Preparing the data\n",
        "\n",
        "We are going to use a `tf.data` pipeline to load the data and generate the images we want to create embedding for.\n",
        "\n",
        "We'll set up the pipeline using a zipped list with images path. The pipeline will load and preprocess the corresponding images."
      ],
      "id": "buKLbgN2K2A-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-MajnkxLHtv"
      },
      "source": [
        "def preprocess_image(filename):\n",
        "    \"\"\"\n",
        "    Load the specified file as a JPEG image, preprocess it and\n",
        "    resize it to the target shape.\n",
        "    \"\"\"\n",
        "\n",
        "    image_string = tf.io.read_file(filename)\n",
        "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.resize(image, target_shape)\n",
        "    return image"
      ],
      "id": "v-MajnkxLHtv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtEUqmGUNWy-"
      },
      "source": [
        "def build_images_dataset(X, path_to_dir):\n",
        "  \"\"\"returns preprocessed images dataset generator\n",
        "  \"\"\"\n",
        "\n",
        "  images = X['image'].apply(lambda x: path_to_dir + x).tolist()\n",
        "\n",
        "  images_dataset = tf.data.Dataset.from_tensor_slices(images)\n",
        "\n",
        "  images_dataset = images_dataset.map(preprocess_image)\n",
        "\n",
        "  images_dataset = images_dataset.batch(32, drop_remainder=False)\n",
        "  images_dataset = images_dataset.prefetch(8)\n",
        "\n",
        "  return images_dataset"
      ],
      "id": "xtEUqmGUNWy-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0AinfW9R6V_"
      },
      "source": [
        "## Setting up the embedding model"
      ],
      "id": "R0AinfW9R6V_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kov67kc8NwN_",
        "outputId": "a9288c08-ddcc-419f-e583-e076f3c7844e"
      },
      "source": [
        "# ResNet50 based embedding model\n",
        "\n",
        "base_cnn = resnet.ResNet50(\n",
        "    weights=\"imagenet\", input_shape=target_shape + (3,), include_top=False\n",
        ")\n",
        "\n",
        "flatten = layers.Flatten()(base_cnn.output)\n",
        "dense1 = layers.Dense(512, activation=\"relu\")(flatten)\n",
        "dense1 = layers.BatchNormalization()(dense1)\n",
        "dense2 = layers.Dense(256, activation=\"relu\")(dense1)\n",
        "dense2 = layers.BatchNormalization()(dense2)\n",
        "output = layers.Dense(256)(dense2)\n",
        "# layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)\n",
        "\n",
        "embedding = Model(base_cnn.input, output, name=\"Embedding\")\n",
        "\n",
        "trainable = False\n",
        "for layer in base_cnn.layers:\n",
        "    if layer.name == \"conv5_block1_out\":\n",
        "        trainable = True\n",
        "    layer.trainable = trainable"
      ],
      "id": "kov67kc8NwN_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7879a997",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbe056ab-8dd9-4873-fdff-48b749e7d682"
      },
      "source": [
        "# vgg based embedding model\n",
        "\n",
        "base_vgg = tf.keras.applications.vgg16.VGG16(\n",
        "    include_top=False,\n",
        "    input_shape=target_shape + (3,)\n",
        ")\n",
        "\n",
        "vgg_embedding = tf.keras.Sequential([\n",
        "                             base_vgg,\n",
        "                             tf.keras.layers.Flatten(),\n",
        "                             tf.keras.layers.Dense(1024, activation=None), # No activation on final dense layer\n",
        "                             tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n",
        "\n",
        "])\n",
        "\n",
        "base_vgg.trainable=False"
      ],
      "id": "7879a997",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYNzIDP-SIa4"
      },
      "source": [
        "# comment in order to train ResNet50 based model\n",
        "# load saved weights\n",
        "\n",
        "embedding = vgg_embedding\n",
        "\n",
        "checkpoint_filepath = '/content/drive/MyDrive/ITC/final_project/Shopee/siamese_model/vgg_embedding_checkpoint'\n",
        "embedding.load_weights(checkpoint_filepath)"
      ],
      "id": "yYNzIDP-SIa4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqrzvqVXXgVe"
      },
      "source": [
        "# Load entire model\n",
        "\n",
        "model_filepath = '/content/drive/MyDrive/ITC/final_project/Shopee/siamese_model/vgg_embedding_model'\n",
        "embedding.load(model_filepath)"
      ],
      "id": "ZqrzvqVXXgVe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdHju4WjWJSX"
      },
      "source": [
        "## Embedding"
      ],
      "id": "xdHju4WjWJSX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZctUsnvVWpS"
      },
      "source": [
        "path_to_dir = '/content/train_images/'\n",
        "X = X_val.copy()\n",
        "\n",
        "\n",
        "# build image data generator\n",
        "images_dataset = build_images_dataset(X, path_to_dir)\n",
        "\n",
        "# embedding\n",
        "image_embeddings = embedding.predict(images_dataset)\n",
        "\n",
        "# saving embeddings and data to csv\n",
        "image_embeddings_dir = '/content/drive/MyDrive/ITC/final_project/Shopee/data/siamese_image_embedding' + file_path\n",
        "X_emb_dir = '/content/drive/MyDrive/ITC/final_project/Shopee/data/siamese_data' + file_path\n",
        "\n",
        "np.savetxt(image_embeddings_dir, image_embeddings, delimiter=\",\")\n",
        "X.to_csv(X_emb_dir)"
      ],
      "id": "RZctUsnvVWpS",
      "execution_count": null,
      "outputs": []
    }
  ]
}